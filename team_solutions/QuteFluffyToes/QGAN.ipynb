{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b64997",
   "metadata": {},
   "source": [
    "The generative model is adapted from here :\n",
    "https://pennylane.ai/qml/demos/tutorial_quantum_gans.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88cc61a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pennylane as qml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b7bf946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noob/.pyenvs/qq/lib/python3.10/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# Pytorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe6d423a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] version 1.4.0, llvm 15.0.4, commit fbe92fd8, linux, python 3.10.9\n",
      "[I 01/29/23 09:16:54.541 24152] [shell.py:_shell_pop_print@23] Graphical python shell detected, using wrapped sys.stdout\n",
      "[Taichi] Starting on arch=x64\n"
     ]
    }
   ],
   "source": [
    "import taichi as ti\n",
    "ti.init(arch=ti.cpu, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f459a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ising_2d import spin_config, monte_carlo_dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f368f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_sample(lx, ly, k, h=0) :\n",
    "    ising_field = spin_config.IsingField(lx, ly)\n",
    "    ising_field.field_init()\n",
    "    mc_obj = monte_carlo_dynamics.MonteCarloDynamics(ising_field)\n",
    "\n",
    "    mag_temp0 = 200000.0\n",
    "    for iter_time in range(ly * lx):\n",
    "        mc_obj.dynamics(k=k, h=h)\n",
    "        if iter_time % 10 == 0:\n",
    "            mag_temp1 = ising_field.mag_py()\n",
    "            if abs(mag_temp0 - mag_temp1) < 0.001:\n",
    "                break\n",
    "            else:\n",
    "                mag_temp0 = mag_temp1\n",
    "\n",
    "    ising_field.off_set()\n",
    "    return ising_field.spin_img.to_numpy()\n",
    "\n",
    "def proxy_loss(spin_glass) :\n",
    "    dx = spin_glass.roll(1, 0)-spin_glass\n",
    "    sx = spin_glass.roll(1, 0)+spin_glass\n",
    "    sy = spin_glass.roll(1, 1)+spin_glass\n",
    "    dy = spin_glass.roll(1, 1)-spin_glass\n",
    "    good = ((dx*dx.conj()).sum() + (dy*dy.conj()).sum())\n",
    "    total = good + ((sx * sx.conj()).sum() + (sy * sy.conj()).sum())\n",
    "    return good / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bfb4d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_qubits = 8 # Total number of qubits / N\n",
    "n_param_qubits = 1  # Number of parameter qubits / N_P\n",
    "q_depth = 8  # Depth of the parameterised quantum circuit / D\n",
    "n_anc_qubits = 1  # Number of ancillary qubits / N_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85c85a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum simulator\n",
    "dev = qml.device(\"lightning.qubit\", wires=n_data_qubits+n_param_qubits+n_anc_qubits)\n",
    "# Enable CUDA device if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "642c5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface=\"torch\", diff_method=\"parameter-shift\")\n",
    "def quantum_circuit(kappa, noise, weights):\n",
    "\n",
    "    # Store kappa in last qubit\n",
    "    qml.RY(math.acos(1-2*kappa), wires=n_data_qubits+n_anc_qubits+n_param_qubits-1)\n",
    "\n",
    "    weights = weights.reshape(q_depth, n_data_qubits+n_anc_qubits)\n",
    "\n",
    "    # Initialise latent vectors\n",
    "    for i in range(n_data_qubits+n_anc_qubits):\n",
    "        qml.RY(noise[i], wires=i)\n",
    "\n",
    "    # Repeated layer\n",
    "    for i in range(q_depth):\n",
    "        # Parameterised layer\n",
    "        for y in range(n_data_qubits+n_anc_qubits):\n",
    "            qml.RY(weights[i][y], wires=y)\n",
    "\n",
    "        # Control Z gates\n",
    "        for y in range(1,n_data_qubits+n_anc_qubits+n_param_qubits):\n",
    "            qml.CZ(wires=[y-1, y])\n",
    "\n",
    "    # Yank the observable for Hadamard-based edge detection from here :\n",
    "    # https://qiskit.org/textbook/ch-applications/quantum-edge-detection.html#Quantum-Hadamard-Edge-Detection-(QHED)\n",
    "    # And directly return qml.expval(M)\n",
    "    \n",
    "    return qml.state()\n",
    "\n",
    "\n",
    "# For further info on how the non-linear transform is implemented in Pennylane\n",
    "# https://discuss.pennylane.ai/t/ancillary-subsystem-measurement-then-trace-out/1532\n",
    "def partial_measure(kappa, noise, weights):\n",
    "    # Non-linear Transform\n",
    "    state = quantum_circuit(kappa, noise, weights)\n",
    "    partial_state = state[:2**(n_data_qubits)]\n",
    "\n",
    "    # Post-Processing\n",
    "    mass = torch.sqrt(torch.sum(partial_state * partial_state.conj()))\n",
    "    post_state = partial_state / mass\n",
    "\n",
    "    return post_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "410be3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kappas': array([0.05      , 0.09444444, 0.13888889, 0.18333333, 0.22777778,\r\n",
      "       0.27222222, 0.31666667, 0.36111111, 0.40555556, 0.45      ]), 'means': [0.9581977105140687, 0.9020747089385986, 0.8743394351005555, 0.8113537323474884, 0.7445275354385376, 0.7039586758613586, 0.6265425270795822, 0.5875770354270935, 0.5138944089412689, 0.5828443007171153]}\r\n"
     ]
    }
   ],
   "source": [
    "!cat profile.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32e6d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'kappas': [0.05      , 0.09444444, 0.13888889, 0.18333333, 0.22777778,\n",
    "       0.27222222, 0.31666667, 0.36111111, 0.40555556, 0.45      ], 'means': [0.9581977105140687, 0.9020747089385986, 0.8743394351005555, 0.8113537323474884, 0.7445275354385376, 0.7039586758613586, 0.6265425270795822, 0.5875770354270935, 0.5138944089412689, 0.5828443007171153]}\n",
    "\n",
    "kappas = data['kappas']\n",
    "means  = data['means']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e7f1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c62bc8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3da0134c10>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def EnergyEstimate(kappa) :\n",
    "    # Approximate the profile by linear interpolation\n",
    "    for i, k in enumerate(kappas) :\n",
    "        if k > kappa : break\n",
    "    if i <= 0 : return 1\n",
    "    return means[i-1] + (means[i]-means[i-1]) * (kappa - kappas[i-1]) / (kappas[i] - kappas[i-1])\n",
    "\n",
    "xx = np.linspace(0.05, 0.4, 25)\n",
    "yy = [EnergyEstimate(x) for x in xx]\n",
    "plt.plot(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed6d56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec213818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumGenerator(nn.Module):\n",
    "    \"\"\"Quantum generator class for the patch method\"\"\"\n",
    "\n",
    "    def __init__(self, q_delta=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_generators (int): Number of sub-generators to be used in the patch method.\n",
    "            q_delta (float, optional): Spread of the random distribution for parameter initialisation.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.q_params = nn.ParameterList(\n",
    "            [\n",
    "                nn.Parameter(q_delta * torch.rand(q_depth * (n_data_qubits+n_anc_qubits)),\n",
    "                             requires_grad=True),\n",
    "            ])\n",
    "\n",
    "    def forward(self, k, z):\n",
    "        amplitudes = partial_measure(k, z, self.q_params[0])\n",
    "        image = torch.sqrt(amplitudes*amplitudes.conj())\n",
    "        image = image.reshape(16, 16)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2f05caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = QuantumGenerator().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "lrG = 0.1\n",
    "num_iter = 1000\n",
    "\n",
    "optG = optim.SGD(generator.parameters(), lr=lrG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3b726f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = np.random.uniform(0.05, 0.4)\n",
    "noise = torch.rand(n_data_qubits+n_anc_qubits, device=device) * math.pi / 2\n",
    "image = generator(kappa, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "061cc9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2218+0.j, dtype=torch.complex128, grad_fn=<DivBackward0>) 0.8145342895166228 tensor(0.3513-0.j, dtype=torch.complex128, grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = proxy_loss(image)\n",
    "b = EnergyEstimate(kappa)\n",
    "c = (a-b)**2\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dc652b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Computing the gradient of circuits that return the state is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m target \u001b[38;5;241m=\u001b[39m EnergyEstimate(kappa)\n\u001b[1;32m     11\u001b[0m mse \u001b[38;5;241m=\u001b[39m (loss \u001b[38;5;241m-\u001b[39m target) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m optG\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.pyenvs/qq/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenvs/qq/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenvs/qq/lib/python3.10/site-packages/torch/autograd/function.py:267\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    264\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    265\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    266\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenvs/qq/lib/python3.10/site-packages/pennylane/interfaces/torch.py:164\u001b[0m, in \u001b[0;36mExecuteTapes.backward\u001b[0;34m(ctx, *dy)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;66;03m# The derivative order is at the maximum. Compute the VJP\u001b[39;00m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;66;03m# in a non-differentiable manner to reduce overhead.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39mUnwrap(\u001b[38;5;241m*\u001b[39mctx\u001b[38;5;241m.\u001b[39mtapes):\n\u001b[0;32m--> 164\u001b[0m             vjp_tapes, processing_fn \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_vjp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m                \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mextend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m             vjps \u001b[38;5;241m=\u001b[39m processing_fn(ctx\u001b[38;5;241m.\u001b[39mexecute_fn(vjp_tapes)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# Gradient function is not a gradient transform\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# (e.g., it might be a device method).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;66;03m# so we cannot support higher-order derivatives.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenvs/qq/lib/python3.10/site-packages/pennylane/gradients/vjp.py:313\u001b[0m, in \u001b[0;36mbatch_vjp\u001b[0;34m(tapes, dys, gradient_fn, reduction, gradient_kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# Loop through the tapes and dys vector\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tape, dy \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tapes, dys):\n\u001b[0;32m--> 313\u001b[0m     g_tapes, fn \u001b[38;5;241m=\u001b[39m \u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     reshape_info\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(g_tapes))\n\u001b[1;32m    316\u001b[0m     processing_fns\u001b[38;5;241m.\u001b[39mappend(fn)\n",
      "File \u001b[0;32m~/.pyenvs/qq/lib/python3.10/site-packages/pennylane/gradients/vjp.py:182\u001b[0m, in \u001b[0;36mvjp\u001b[0;34m(tape, dy, gradient_fn, gradient_kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m gradient_tapes, fn \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocessing_fn\u001b[39m(results, num\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# postprocess results to compute the Jacobian\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     jac \u001b[38;5;241m=\u001b[39m fn(results)\n",
      "File \u001b[0;32m~/.pyenvs/qq/lib/python3.10/site-packages/pennylane/transforms/batch_transform.py:330\u001b[0m, in \u001b[0;36mbatch_transform.__call__\u001b[0;34m(self, *targs, **tkwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device_wrapper(\u001b[38;5;241m*\u001b[39mtargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtkwargs)(qnode)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(qnode, qml\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39mQuantumTape):\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;66;03m# Input is a quantum tape.\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;66;03m# tapes, fn = some_transform(tape, *transform_args)\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(qnode, (qml\u001b[38;5;241m.\u001b[39mQNode, qml\u001b[38;5;241m.\u001b[39mExpvalCost)):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;66;03m# Input is a QNode:\u001b[39;00m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;66;03m# result = some_transform(qnode, *transform_args)(*qnode_args)\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     wrapper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode_wrapper(qnode, targs, tkwargs)\n",
      "File \u001b[0;32m~/.pyenvs/qq/lib/python3.10/site-packages/pennylane/transforms/batch_transform.py:418\u001b[0m, in \u001b[0;36mbatch_transform._tape_wrapper.<locals>.<lambda>\u001b[0;34m(tape)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tape_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtkwargs):\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m tape: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenvs/qq/lib/python3.10/site-packages/pennylane/transforms/batch_transform.py:402\u001b[0m, in \u001b[0;36mbatch_transform.construct\u001b[0;34m(self, tape, *args, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expand \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m     tape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand_fn(tape, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 402\u001b[0m tapes, processing_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processing_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     processing_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: x\n",
      "File \u001b[0;32m~/.pyenvs/qq/lib/python3.10/site-packages/pennylane/gradients/parameter_shift.py:622\u001b[0m, in \u001b[0;36mparam_shift\u001b[0;34m(tape, argnum, shifts, gradient_recipes, fallback_fn, f0)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Transform a QNode to compute the parameter-shift gradient of all gate\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03mparameters with respect to its inputs.\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03m     [ 0.69916862  0.34072424  0.69202359]]\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(m\u001b[38;5;241m.\u001b[39mreturn_type \u001b[38;5;129;01mis\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mmeasurements\u001b[38;5;241m.\u001b[39mState \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39mmeasurements):\n\u001b[0;32m--> 622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing the gradient of circuits that return the state is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    624\u001b[0m     )\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m argnum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tape\u001b[38;5;241m.\u001b[39mtrainable_params:\n\u001b[1;32m    627\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    628\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to compute the gradient of a tape with no trainable parameters. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    629\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this is unintended, please mark trainable parameters in accordance with the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchosen auto differentiation framework, or via the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtape.trainable_params\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m property.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    631\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Computing the gradient of circuits that return the state is not supported."
     ]
    }
   ],
   "source": [
    "for iterations in range(num_iter) :\n",
    "    kappa = np.random.uniform(0.05, 0.4)\n",
    "    noise = torch.rand(n_data_qubits+n_anc_qubits, device=device) * math.pi / 2\n",
    "    \n",
    "    generator.zero_grad()\n",
    "    image = generator(kappa, noise)\n",
    "\n",
    "    loss = proxy_loss(image) # Simulated \n",
    "    target = EnergyEstimate(kappa)\n",
    "    \n",
    "    mse = (loss - target) ** 2\n",
    "    mse.backward()\n",
    "    \n",
    "    optG.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c74094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f44ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quantum",
   "language": "python",
   "name": "qq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
